import os
import cv2
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
import tensorflow.keras.backend as K
from tensorflow.keras.utils import custom_object_scope

# Aseg√∫rate de que el modelo .h5 est√© bien copiado y sin corrupci√≥n
MODEL_PATH = "HSU_detection_mobilenetJetson.h5"

class Model:
    def __init__(self):
        print("üöÄ Cargando modelo .h5 con capa personalizada...")

        with custom_object_scope({'KerasLayer': hub.KerasLayer}):
            self.model = tf.keras.models.load_model("HSU_detection_mobilenetJetson.h5")
        print(1.1)
        self.labels = {0: "H", 1: "S", 2: "U", 3: "?"}  # puedes ajustar los labels si necesitas

    def predict_image(self, image):
        image_resized = cv2.resize(image, (224, 224))
        image_normalized = image_resized.astype(np.float32) / 255.0
        input_tensor = np.expand_dims(image_normalized, axis=0)
        prediction = self.model.predict(input_tensor)
        class_id = int(np.argmax(prediction))
        return self.labels.get(class_id, "?")

# Configura los pipelines CSI
def gstreamer_pipeline(sensor_id=0):
    return (
        f"nvarguscamerasrc sensor-id={sensor_id} ! "
        f"video/x-raw(memory:NVMM), width=640, height=480, format=NV12, framerate=30/1 ! "
        f"nvvidconv flip-method=0 ! video/x-raw, format=BGRx ! "
        f"videoconvert ! video/x-raw, format=BGR ! appsink"
    )
print(1)
# Inicializa modelo
model = Model()
print("modelo cargado")
# Abrir ambas c√°maras
cap0 = cv2.VideoCapture(gstreamer_pipeline(0), cv2.CAP_GSTREAMER)
cap1 = cv2.VideoCapture(gstreamer_pipeline(1), cv2.CAP_GSTREAMER)
print(3)
if not cap0.isOpened():
    print("‚ùå No se pudo abrir cam0")
if not cap1.isOpened():
    print("‚ùå No se pudo abrir cam1")
print("‚úÖ C√°maras abiertas. Presiona Ctrl+C para salir.")

try:
    while True:
        ret0, frame0 = cap0.read()
        ret1, frame1 = cap1.read()

        detection = Nonekkkkkkkk
        if ret0:
            frame0 = cv2.rotate(frame0, cv2.ROTATE_180)
            det0 = model.predict_image(frame0)
            if det0 != "?":
                detection = det0
                print(f"üì∑ cam0 detect√≥: {detection}")

        if ret1:
            frame1 = cv2.rotate(frame1, cv2.ROTATE_180)
            det1 = model.predict_image(frame1)
            if det1 != "?":
                detection = det1
                print(f"üì∑ cam1 detect√≥: {detection}")

        if detection is None:
            print("üîç No se detect√≥ nada en esta iteraci√≥n.")
except KeyboardInterrupt:
    print("üõë Interrupci√≥n del usuario. Cerrando...")

cap0.release()
cap1.release()
